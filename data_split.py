from datasets import load_from_disk, DatasetDict, Dataset
from sklearn.model_selection import train_test_split

def split_existing_hf_dataset(
    data_path="processed/context",       # âœ… æ•°æ®é›†è·¯å¾„
    test_size=0.1,                       # âœ… éªŒè¯é›†å æ¯”
    seed=42,                             # âœ… éšæœºç§å­
    save_path=None                       # âœ… æ˜¯å¦ä¿å­˜åˆ‡åˆ†åçš„æ•°æ®
) -> DatasetDict:
    print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†ï¼š{data_path}")
    dataset = load_from_disk(data_path)

    # å¦‚æœå·²ç»æ˜¯ DatasetDict ä¸”åŒ…å« validationï¼Œä¸é‡å¤åˆ‡åˆ†
    if isinstance(dataset, DatasetDict):
        if "validation" in dataset:
            print("âœ… å·²å« validationï¼Œè·³è¿‡åˆ‡åˆ†ã€‚")
            return dataset
        else:
            dataset = dataset["train"]

    print(f"âœ‚ï¸ æ­£åœ¨æŒ‰æ¯”ä¾‹ {test_size} åˆ‡åˆ†éªŒè¯é›†...")

    # â— ä¿®æ­£å…³é”®ç‚¹ï¼šå°† dataset è½¬ä¸º list å†åˆ‡åˆ†
    dataset_list = dataset.to_list()
    train_data, val_data = train_test_split(dataset_list, test_size=test_size, random_state=seed)

    result = DatasetDict({
        "train": Dataset.from_list(train_data),
        "validation": Dataset.from_list(val_data)
    })

    if save_path:
        print(f"ğŸ’¾ ä¿å­˜åˆ°ï¼š{save_path}")
        result.save_to_disk(save_path)

    return result

if __name__ == "__main__":
    split_existing_hf_dataset(
        data_path="processed/example",
        test_size=0.1,
        seed=42,
        save_path="processed/example_split"
    )
