[
    {
        "idx": 2,
        "text": " Linguistic style is an integral component of language.",
        "labels": "BAC"
    },
    {
        "idx": 2,
        "text": "Recent advances in the development of style representations have increasingly used training objectives from authorship verification (AV){''}:'' Do two texts have the same author? The assumption underlying the AV training task (same author approximates same writing style) enables self-supervised and, thus, extensive training.",
        "labels": "BAC"
    },
    {
        "idx": 2,
        "text": "However, a good performance on the AV task does not ensure good {``}general-purpose{''} style representations.",
        "labels": "GAP"
    },
    {
        "idx": 2,
        "text": "For example, as the same author might typically write about certain topics, representations trained on AV might also encode content information instead of style alone.",
        "labels": "GAP"
    },
    {
        "idx": 2,
        "text": "We introduce a variation of the AV training task that controls for content using conversation or domain labels.",
        "labels": "PUR"
    },
    {
        "idx": 2,
        "text": "We evaluate whether known style dimensions are represented and preferred over content information through an original variation to the recently proposed STEL framework.",
        "labels": "MTD"
    },
    {
        "idx": 2,
        "text": "We find that representations trained by controlling for conversation are better than representations trained with domain or no content control at representing style independent from content.",
        "labels": "CLN"
    },
    {
        "idx": 3,
        "text": "A popular approach to decrease the need for costly manual annotation of large data sets is weak supervision, which introduces problems of noisy labels, coverage and bias.",
        "labels": "BAC"
    },
    {
        "idx": 3,
        "text": "Methods for overcoming these problems have either relied on discriminative models, trained with cost functions specific to weak supervision, and more recently, generative models, trying to model the output of the automatic annotation process.",
        "labels": "BAC"
    },
    {
        "idx": 3,
        "text": "In this work, we explore a novel direction of generative modeling for weak supervision{''}:'",
        "labels": "PUR"
    }
]